{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Data Science Tools and Ecosystem",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Objectives:**\n\n* List popular languages for Data Science.\n* Create ordered and unordered lists in Markdown.\n* Write comments in Python code.\n* Perform basic calculations in Python.\n* Format text with Markdown headings. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this notebook, Data Science Tools and Ecosystem are summarized.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Python:  Python is arguably the most popular language for data science. It has a gentle learning curve, and a rich ecosystem of libraries specifically designed for data analysis, machine learning, and visualization (e.g., Pandas, NumPy, Scikit-learn, Matplotlib).\n\n1. R: R is a statistical programming language with powerful tools for data analysis and visualization. It excels in statistical computing and creating high-quality graphics. The tidyverse, a collection of R packages, has gained popularity for its intuitive approach to data manipulation.\n\n1. SQL: SQL (Structured Query Language) is essential for working with relational databases. Data scientists 1  use SQL to extract, filter, and aggregate data from databases, which often serve as the foundation for their analyses.   \n\n1. Julia: Julia is a newer language gaining traction in data science. It's designed for high-performance numerical computing, making it well-suited for tasks involving large datasets and complex models.\n\n1. Scala: Scala often plays a role in big data applications. Its integration with Apache Spark, a powerful framework for distributed data processing, makes it a valuable tool for data scientists working with massive datasets.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Some of the commonly used libraries used by Data Scientists include:\n\nFor Data Manipulation and Analysis:\n\n1. Pandas: Provides powerful and flexible data structures (like DataFrames) for efficiently cleaning, transforming, and analyzing data. Think of it as Excel on steroids.\n1. NumPy: The foundation for numerical computing in Python. It introduces arrays for handling large datasets and provides tools for mathematical operations.\n\n\nFor Machine Learning:\n\n1. Scikit-learn: A comprehensive library with a wide range of machine learning algorithms for classification, regression, clustering, dimensionality reduction, and model selection. It's1 your go-to for building and evaluating models.   \n1. TensorFlow/Keras: Popular for deep learning tasks, these libraries provide tools for building and training neural networks. TensorFlow is more powerful and customizable, while Keras offers a user-friendly interface.\nPyTorch: Another deep learning library known for its flexibility and dynamic computation graph, making it suitable for research and complex model architectures.\n\n\nFor Data Visualization:\n\n1. Matplotlib: A versatile library for creating static, interactive, and animated visualizations. It provides a wide variety of plot types and customization options.\n1. Seaborn: Built on top of Matplotlib, Seaborn offers a higher-level interface for creating statistically informative and visually appealing plots.\n\n\nFor Other Tasks:\n\n1. SciPy: Builds on NumPy and provides additional functionality for scientific computing, including optimization, linear algebra, and signal processing.\n1. Statsmodels: Focuses on statistical models and provides tools for statistical testing, estimation, and analysis.\nNLTK (Natural Language Toolkit): A leading platform for working with human language data. It provides tools for tasks like tokenization, stemming, and sentiment analysis.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "| Data Science Tools      |\n|-------------------------|\n| Jupyter Notebook        |\n| RStudio                 |\n| Apache Zeppelin         |",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Below are a few examples of evaluating arithmetic expressions in Python.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# This a simple arithmetic expression to mutiply then add integers\n(3*4)+5",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "17"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# This will convert 200 minutes to hours by dividing by 60\nhours = 200 / 60 \n\nprint(hours) ",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "3.3333333333333335\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "## Author\nNicolas HAMELIN",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}